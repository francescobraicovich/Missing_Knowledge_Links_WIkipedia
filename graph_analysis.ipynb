{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_graph import build_graph\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph found. Loading graph, links and categories.\n",
      "Number of nodes: 3381 , Number of edges: 330293\n"
     ]
    }
   ],
   "source": [
    "depth = 2\n",
    "start_page = \"Cumulative distribution function\" \n",
    "\n",
    "graph, links_dict, categories_dict = build_graph(start_page, depth, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neighbors import get_common_neighbors, get_total_neighbors, get_jaccard_coefficient\n",
    "\n",
    "adjacency_matrix = nx.adjacency_matrix(graph).todense()\n",
    "adjacency_matrix.astype(int)\n",
    "common_neighbors_matrix = get_common_neighbors(adjacency_matrix)\n",
    "total_neighbors_matrix = get_total_neighbors(adjacency_matrix, common_neighbors_matrix)\n",
    "jaccard_similarity_matrix = get_jaccard_coefficient(common_neighbors_matrix, total_neighbors_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.01, N Clusters: 48, Silhouette Score: -0.171\n",
      "Epsilon: 0.041, N Clusters: 51, Silhouette Score: -0.123\n",
      "Epsilon: 0.071, N Clusters: 50, Silhouette Score: 0.065\n",
      "Epsilon: 0.102, N Clusters: 48, Silhouette Score: 0.066\n",
      "Epsilon: 0.133, N Clusters: 50, Silhouette Score: 0.063\n",
      "Epsilon: 0.163, N Clusters: 42, Silhouette Score: 0.222\n",
      "Epsilon: 0.194, N Clusters: 41, Silhouette Score: 0.265\n",
      "Epsilon: 0.225, N Clusters: 41, Silhouette Score: 0.215\n",
      "Epsilon: 0.256, N Clusters: 36, Silhouette Score: -0.107\n",
      "Epsilon: 0.286, N Clusters: 35, Silhouette Score: -0.106\n",
      "Epsilon: 0.317, N Clusters: 33, Silhouette Score: -0.112\n",
      "\n",
      "Warning: The noise cluster is too large, Noise size: 1053, Threshold: 338.1\n",
      "Subclustering the noise cluster\n",
      "\n",
      "Warning: The noise cluster is too large, Noise size: 854, Threshold: 105.30000000000001\n",
      "Subclustering the noise cluster\n",
      "\n",
      "Warning: The noise cluster is too large, Noise size: 382, Threshold: 85.4\n",
      "Subclustering the noise cluster\n",
      "\n",
      "Warning: The noise cluster is too large, Noise size: 162, Threshold: 38.2\n",
      "Subclustering the noise cluster\n",
      "--------------------------------------------------\n",
      "Final Silhouette Score: 0.2796094146194735\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from dbscan import dbscan_from_similarity\n",
    "\n",
    "# combine the adjacency matrix and the jaccard similarity matrix\n",
    "clustering_matrix = jaccard_similarity_matrix + adjacency_matrix\n",
    "\n",
    "# find the maximum value in the matrix\n",
    "max_val = np.max(clustering_matrix)\n",
    "\n",
    "# set the diagonal to the maximum value\n",
    "np.fill_diagonal(clustering_matrix, max_val)\n",
    "\n",
    "cluster_labels = dbscan_from_similarity(clustering_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 74\n",
      "Cluster sizes: [35, 6, 5, 7, 5, 6, 24, 5, 6, 5, 51, 25, 5, 9, 13, 21, 6, 5, 100, 18, 27, 6, 17, 30, 8, 10, 35, 8, 32, 78, 38, 9, 9, 80, 258, 184, 388, 170, 182, 123, 314, 5, 5, 5, 5, 5, 6, 9, 7, 56, 7, 44, 6, 7, 32, 466, 6, 7, 5, 10, 6, 13, 8, 5, 8, 6, 8, 11, 6, 6, 116, 5, 121, 6, 0]\n",
      "Max cluster size: 466, Min cluster size: 0\n"
     ]
    }
   ],
   "source": [
    "# get the number of clusters and the number of nodes in each cluster\n",
    "n_clusters = len(set(cluster_labels))\n",
    "cluster_sizes = [np.sum(cluster_labels == i) for i in range(-1, n_clusters)]\n",
    "print(f\"Number of clusters: {n_clusters}\")\n",
    "print(f'Cluster sizes: {cluster_sizes}')\n",
    "\n",
    "max_size = max(cluster_sizes)\n",
    "min_size = min(cluster_sizes)\n",
    "\n",
    "print(f\"Max cluster size: {max_size}, Min cluster size: {min_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 nodes in cluster 69, with the start page:\n",
      "Gaius Terentilius Harsa\n",
      "Consul\n",
      "Terentilia gens\n",
      "Bürgerliches Gesetzbuch\n",
      "Civil Code of Japan\n",
      "Code of Hammurabi\n",
      "Corpus Juris Civilis\n",
      "Napoleonic Code\n",
      "Philippine legal codes\n",
      "United States Code\n",
      "Acta Senatus\n",
      "Andrew Lintott\n",
      "Centuria\n",
      "Equestrians\n",
      "Gaius Licinius Stolo\n",
      "James Hampton (priest)\n",
      "Lex Hortensia\n",
      "Lex Trebonia (448 BC)\n",
      "Lily Ross Taylor\n",
      "Lucius Sextius Lateranus\n",
      "Lucius Sicinius Vellutus\n",
      "Lucius Valerius Poplicola Potitus\n",
      "Master of the Horse\n",
      "Monte Sacro\n",
      "Nobiles\n",
      "Outline of political science\n",
      "Plebeians\n",
      "Quintus Hortensius (dictator)\n",
      "Quintus Publilius Philo\n",
      "Veto\n",
      "Agen\n",
      "Argos, Peloponnese\n",
      "Consularis\n",
      "Hypatos\n",
      "Livadeia\n",
      "Sufet\n",
      "Titus Tatius\n",
      "Annales maximi\n",
      "Antony's Parthian War\n",
      "Ariarathes V\n",
      "Ascanius\n",
      "Bacchanalia\n",
      "Battle of Chaeronea (86 BC)\n",
      "Battle of the Caudine Forks\n",
      "Bituitus\n",
      "Brennus (4th century BC)\n",
      "Corsicans\n",
      "Dardanians (Trojan)\n",
      "Donations of Alexandria\n",
      "Epitome\n",
      "Gaius Antonius (brother of Mark Antony)\n",
      "Gaius Scribonius Curio (consul)\n",
      "Gaius Servilius Glaucia\n",
      "Gnaeus Gellius\n",
      "Henry Francis Pelham\n",
      "Hercynian Forest\n",
      "Lacuna (manuscripts)\n",
      "Laodicea on the Lycus\n",
      "Lex Oppia\n",
      "Licinius Macer\n",
      "Marcus Aemilius Lepidus (consul 187 BC)\n",
      "Marcus Aemilius Lepidus Minor\n",
      "Marcus Licinius Crassus (consul 30 BC)\n",
      "Marcus Manlius Capitolinus\n",
      "Nicomachus Flavianus (son)\n",
      "Octavia the Younger\n",
      "Oxyrhynchus\n",
      "Pact of Misenum\n",
      "Palimpsest\n",
      "Penguin Classics\n",
      "Phraates II\n",
      "Publius Decius Mus (consul 312 BC)\n",
      "Quintus Caecilius Metellus Balearicus\n",
      "Rape of the Sabine women\n",
      "Sallentini\n",
      "Sine qua non\n",
      "Syrian Wars\n",
      "Titus Annius Milo\n",
      "Treaty of Apamea\n",
      "Vercingetorix\n",
      "Viriathus\n",
      "Wolf\n",
      "Gaius Asinius Pollio (consul 40 BC)\n",
      "Aebutia gens\n",
      "Anthypatos\n",
      "Aternia gens\n",
      "Augury\n",
      "Bonifacius\n",
      "Byzantine Senate\n",
      "Curiatia gens\n",
      "Curtia gens\n",
      "Flavius Aetius\n",
      "Foslia gens\n",
      "Gegania gens\n",
      "Harper's Dictionary of Classical Antiquities\n",
      "Herminia gens\n",
      "Horatia gens\n",
      "J. B. Bury\n",
      "Lartia gens\n",
      "Leges Genuciae\n",
      "Lex Canuleia\n",
      "Lex Ogulnia\n",
      "Menenia gens\n",
      "Metilia gens\n",
      "Numicia gens\n",
      "Orestes (father of Romulus Augustulus)\n",
      "Oxford Classical Dictionary\n",
      "Oxford Dictionary of Byzantium\n",
      "Pollia gens\n",
      "Ricimer\n",
      "Romilia gens\n",
      "Sestia gens\n",
      "Stilicho\n",
      "Tarpeia gens\n",
      "Tarquitia gens\n",
      "Vir illustris\n"
     ]
    }
   ],
   "source": [
    "# find the cluster of the start page\n",
    "start_page_cluster = cluster_labels[0]\n",
    "\n",
    "# find the nodes in the same cluster as the start page\n",
    "start_page_cluster_nodes = [node for node, cluster in zip(graph.nodes, cluster_labels) if cluster == start_page_cluster]\n",
    "\n",
    "# find the dimension of the start page cluster\n",
    "start_page_cluster_dim = len(start_page_cluster_nodes)\n",
    "\n",
    "print(f\"{start_page_cluster_dim} nodes in cluster {start_page_cluster}, with the start page:\")\n",
    "for node in start_page_cluster_nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity thresholds: \n",
      "Weak quantile threshold: 0.9075144508670521\n",
      "Strong quantile threshold: 0.9597069597069597\n"
     ]
    }
   ],
   "source": [
    "# set the diagonal of the adjacency matrix to 0\n",
    "np.fill_diagonal(adjacency_matrix, 0)\n",
    "boolean_adjacency_matrix = adjacency_matrix > 0\n",
    "masked_similarity_matrix = jaccard_similarity_matrix[boolean_adjacency_matrix]\n",
    "\n",
    "# find weak quantile threshold\n",
    "weak_quantile_threshold = 0.95\n",
    "weak_threshold = np.quantile(masked_similarity_matrix, weak_quantile_threshold)\n",
    "\n",
    "# find strong quantile threshold\n",
    "strong_quantile_threshold = 0.99\n",
    "strong_threshold = np.quantile(masked_similarity_matrix, strong_quantile_threshold)\n",
    "\n",
    "# print the thresholds\n",
    "print(f'Similarity thresholds: ')\n",
    "print(f'Weak quantile threshold: {weak_threshold}')\n",
    "print(f'Strong quantile threshold: {strong_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing link candidates: 866\n"
     ]
    }
   ],
   "source": [
    "from missing_links import find_missing_link_candidates, print_missing_links_dict\n",
    "\n",
    "missing_link_candidates, missing_link_candidates_matrix = find_missing_link_candidates(graph, jaccard_similarity_matrix, cluster_labels, weak_threshold, strong_threshold)\n",
    "\n",
    "print(f\"Number of missing link candidates: {len(missing_link_candidates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 256, 447, 107, 235, 1290, 280, 1203, 704, 667, 744, 300, 277, 957, 578, 25, 375, 435, 84, 25, 43, 181, 143, 208, 207, 138, 212, 231, 177, 202, 135, 140, 222, 143, 314, 197, 204, 45, 209, 153, 204, 181, 201, 213, 200, 552, 229, 31, 251, 238, 248, 223, 232, 253, 156, 38, 71, 276, 209, 393, 37, 64, 13, 233, 214, 280, 228, 231, 238, 202, 341, 214, 305, 200, 155, 235, 216, 220, 71, 144, 221, 153, 209, 236, 43, 165, 227, 215, 351, 222, 157, 144, 143, 213, 512, 216, 28, 166, 270, 208, 515, 163, 337, 103, 202, 214, 213, 143, 208, 282, 134, 136, 207, 207, 202, 142, 168, 459, 411, 20, 15, 222, 200, 216, 205, 214, 180, 310, 323, 210, 251, 219, 242, 220, 208, 308, 215, 204, 138, 200, 202, 181, 154, 158, 298, 200, 175, 556, 181, 498, 233, 17, 256, 135, 240, 603, 239, 227, 208, 156, 211, 145, 137, 153, 254, 200, 209, 209, 203, 260, 234, 139, 206, 141, 138, 205, 222, 291, 163, 185, 11, 328, 253, 49, 205, 29, 95, 225, 208, 66, 131, 158, 646, 252, 139, 152, 201, 48, 43, 110, 19, 274, 288, 248, 205, 264, 144, 201, 217, 145, 207, 146, 144, 153, 227, 219, 232, 223, 97, 168, 216, 148, 224, 239, 204, 154, 42, 208, 484, 681, 517, 217, 207, 194, 210, 208, 241, 161, 212, 212, 204, 220, 214, 67, 16, 163, 78, 201, 229, 135, 184, 152, 200, 225, 143, 211, 203, 490, 555, 50, 151, 227, 151, 218, 198, 136, 338, 45, 410, 444, 298, 67, 39, 404, 371, 312, 359, 419, 399, 401, 400, 405, 815, 428, 46, 467, 398, 437, 322, 310, 425, 429, 546, 444, 334, 312, 302, 435, 288, 403, 415, 380, 363, 400, 603, 465, 530, 503, 316, 405, 423, 418, 292, 74, 426, 383, 1092, 484, 297, 297, 403, 410, 405, 297, 404, 417, 415, 419, 453, 407, 399, 406, 350, 347, 308, 122, 400, 468, 420, 420, 386, 436, 365, 439, 299, 399, 420, 386, 319, 412, 428, 423, 304, 357, 403, 413, 17, 461, 343, 314, 384, 293, 363, 541, 43, 298, 406, 41, 401, 451, 310, 304, 30, 141, 324, 482, 296, 399, 454, 474, 415, 515, 378, 388, 387, 421, 417, 421, 459, 465, 292, 447, 446, 417, 122, 28, 40, 393, 325, 313, 337, 353, 644, 295, 293, 305, 419, 464, 637, 445, 426, 425, 440, 122, 491, 466, 381, 380, 389, 413, 31, 361, 88, 18, 298, 418, 33, 419, 315, 444, 472, 419, 297, 287, 328, 498, 433, 484, 436, 415, 455, 443, 294, 442, 414, 410, 426, 295, 423, 416, 347, 15, 19, 19, 440, 431, 405, 329, 449, 428, 385, 380, 299, 384, 300, 290, 448, 413, 433, 62, 318, 465, 407, 424, 442, 415, 442, 30, 421, 409, 390, 297, 46, 295, 407, 482, 307, 349, 434, 227, 432, 480, 71, 415, 301, 421, 291, 419, 301, 315, 290, 420, 425, 432, 385, 378, 507, 69, 526, 446, 741, 411, 412, 388, 296, 874, 459, 300, 417, 478, 319, 303, 113, 525, 429, 451, 303, 302, 329, 40, 449, 422, 386, 494, 454, 301, 295, 305, 304, 23, 18, 459, 526, 326, 369, 415, 379, 388, 808, 408, 384, 483, 597, 392, 419, 402, 416, 429, 424, 424, 406, 430, 478, 293, 456, 411, 396, 584, 411, 501, 413, 493, 399, 395, 423, 401, 423, 346, 400, 443, 417, 405, 401, 404, 400, 442, 490, 458, 470, 442, 389, 429, 420, 405, 422, 396, 433, 570, 476, 309, 612, 431, 128, 479, 401, 418, 67, 387, 383, 393, 120, 134, 318, 372, 310, 452, 319, 314, 435, 317, 313, 473, 312, 581, 302, 412, 308, 404, 306, 369, 401, 424, 480, 550, 402, 429, 467, 427, 409, 302, 309, 408, 404, 529, 412, 420, 383, 458, 466, 443, 361, 135, 304, 109, 297, 358, 70, 331, 294, 81, 413, 408, 395, 495, 432, 416, 511, 577, 425, 298, 311, 40, 14, 23, 29, 16, 62, 20, 114, 41, 20, 169, 45, 37, 36, 21, 45, 39, 39, 113, 56, 16, 59, 76, 176, 539, 216, 52, 514, 30, 44, 46, 151, 109, 97, 15, 81, 82, 54, 58, 74, 27, 40, 280, 78, 30, 56, 422, 17, 35, 86, 48, 87, 130, 30, 563, 31, 385, 38, 31, 602, 33, 31, 30, 40, 365, 67, 21, 24, 290, 141, 427, 538, 368, 225, 37, 51, 66, 101, 34, 43, 484, 180, 97, 550, 32, 209, 22, 19, 76, 62, 355, 22, 240, 129, 388, 30, 556, 244, 132, 50, 177, 59, 59, 47, 30, 36, 36, 428, 28, 470, 76, 54, 42, 68, 119, 39, 407, 111, 240, 67, 51, 62, 80, 59, 240, 41, 54, 62, 96, 270, 96, 136, 228, 293, 108, 432, 88, 138, 40, 295, 109, 343, 203, 190, 268, 207, 23, 595, 214, 328, 119, 149, 78, 216, 62, 63, 66, 22, 307, 63, 393, 281, 295, 405, 151, 99, 87, 116, 128, 164, 159, 89, 88, 179, 111, 231, 120, 54, 96, 66, 205, 229, 497, 278, 64, 214, 86, 88, 178, 233, 225, 220, 75, 186, 270, 205, 210, 326, 231, 178, 83, 60, 219, 272, 200, 181, 306, 117, 210, 36, 19, 214, 299, 280, 249, 173, 277, 20, 190, 51, 306, 495, 113, 47, 291, 61, 49, 173, 202, 226, 218, 316, 212, 111, 203, 250, 66, 73, 67, 367, 178, 329, 369, 441, 64, 39, 58, 305, 231, 72, 344, 81, 61, 295, 210, 83, 23, 271, 197, 266, 275, 185, 183, 39, 63, 73, 62, 381, 199, 29, 55, 213, 221, 158, 326, 19, 27, 193, 201, 198, 279, 226, 151, 68, 60, 62, 106, 282, 268, 101, 195, 66, 68, 222, 75, 33, 56, 72, 143, 115, 71, 225, 37, 81, 111, 116, 70, 21, 35, 216, 309, 274, 212, 217, 82, 274, 50, 266, 436, 56, 66, 22, 27, 149, 254, 127, 460, 60, 65, 59, 61, 109, 206, 78, 65, 39, 66, 169, 236, 272, 76, 198, 38, 267, 526, 95, 197, 117, 419, 283, 206, 59, 227, 268, 267, 285, 273, 303, 214, 300, 204, 220, 208, 217, 189, 52, 208, 272, 327, 59, 51, 40, 255, 623, 64, 98, 151, 33, 212, 37, 44, 38, 147, 229, 270, 64, 60, 36, 52, 150, 332, 223, 108, 268, 349, 226, 221, 58, 59, 270, 109, 238, 60, 60, 50, 37, 82, 65, 209, 181, 208, 50, 34, 338, 179, 56, 251, 163, 98, 136, 97, 316, 79, 167, 319, 388, 81, 92, 171, 172, 49, 273, 74, 92, 27, 116, 54, 38, 39, 259, 37, 300, 50, 198, 148, 190, 49, 296, 88, 74, 268, 219, 107, 26, 61, 248, 290, 284, 251, 176, 95, 66, 263, 20, 61, 195, 641, 269, 570, 286, 196, 274, 266, 317, 278, 293, 308, 311, 79, 191, 309, 197, 201, 216, 222, 201, 165, 175, 337, 210, 44, 388, 363, 212, 200, 117, 159, 105, 134, 35, 130, 58, 267, 146, 345, 273, 174, 290, 319, 158, 168, 308, 172, 94, 192, 114, 140, 21, 209, 197, 42, 212, 31, 37, 193, 416, 273, 265, 282, 281, 193, 220, 277, 215, 210, 41, 274, 460, 290, 482, 202, 263, 269, 264, 242, 319, 201, 289, 84, 64, 103, 349, 422, 84, 368, 372, 193, 26, 50, 140, 228, 153, 526, 98, 31, 268, 243, 264, 84, 265, 134, 48, 32, 23, 478, 93, 81, 61, 43, 64, 36, 71, 55, 139, 220, 24, 112, 205, 321, 74, 367, 30, 27, 198, 238, 158, 21, 25, 55, 99, 30, 93, 38, 280, 82, 271, 209, 219, 72, 193, 229, 18, 188, 37, 30, 48, 62, 130, 16, 152, 268, 191, 270, 56, 81, 141, 107, 205, 226, 48, 82, 310, 418, 144, 119, 274, 284, 60, 33, 109, 92, 122, 251, 37, 62, 130, 291, 27, 194, 35, 185, 54, 64, 51, 25, 185, 308, 372, 199, 90, 73, 44, 466, 51, 195, 35, 34, 23, 31, 139, 166, 171, 474, 54, 46, 139, 58, 78, 76, 215, 124, 19, 292, 231, 67, 273, 185, 80, 106, 270, 274, 370, 197, 215, 266, 141, 351, 76, 203, 61, 68, 215, 176, 299, 218, 257, 239, 74, 226, 43, 25, 39, 79, 231, 22, 170, 21, 78, 318, 197, 87, 62, 197, 218, 256, 178, 127, 148, 321, 614, 61, 63, 275, 318, 296, 276, 209, 227, 202, 184, 55, 88, 55, 500, 214, 62, 94, 171, 47, 270, 20, 250, 91, 66, 225, 278, 76, 153, 188, 192, 194, 302, 203, 151, 28, 171, 174, 148, 165, 56, 58, 219, 285, 241, 204, 205, 71, 245, 195, 216, 228, 258, 391, 269, 15, 84, 53, 238, 210, 229, 152, 50, 84, 110, 27, 258, 146, 79, 24, 288, 227, 255, 332, 260, 261, 330, 81, 322, 253, 65, 227, 301, 210, 83, 269, 150, 84, 223, 271, 440, 46, 309, 88, 93, 19, 32, 17, 54, 151, 18, 48, 339, 678, 50, 93, 173, 308, 269, 348, 28, 397, 282, 345, 231, 24, 189, 209, 144, 159, 195, 48, 103, 42, 15, 35, 108, 200, 37, 84, 72, 71, 247, 527, 83, 51, 93, 231, 245, 337, 183, 100, 278, 139, 313, 179, 64, 60, 59, 92, 225, 311, 55, 190, 85, 49, 238, 264, 239, 25, 158, 122, 407, 111, 123, 148, 110, 96, 80, 97, 91, 96, 322, 179, 79, 86, 104, 140, 198, 195, 337, 123, 79, 236, 49, 149, 218, 62, 71, 69, 103, 96, 119, 109, 30, 357, 276, 421, 165, 295, 324, 194, 80, 83, 124, 227, 63, 98, 107, 80, 30, 81, 337, 257, 21, 263, 197, 63, 79, 311, 220, 188, 202, 25, 202, 206, 183, 269, 15, 165, 96, 110, 224, 135, 170, 179, 151, 308, 294, 150, 148, 83, 315, 102, 277, 208, 111, 19, 435, 402, 155, 257, 74, 75, 17, 76, 73, 338, 292, 276, 53, 280, 259, 263, 234, 28, 113, 157, 196, 41, 232, 151, 286, 112, 73, 83, 202, 268, 618, 67, 202, 214, 45, 207, 25, 269, 129, 264, 16, 272, 133, 278, 19, 194, 234, 298, 237, 294, 269, 415, 192, 17, 191, 228, 223, 234, 201, 152, 254, 324, 263, 159, 270, 208, 31, 106, 63, 55, 48, 58, 31, 152, 102, 59, 279, 181, 301, 195, 464, 334, 204, 104, 83, 211, 156, 80, 104, 147, 34, 182, 72, 57, 59, 208, 217, 103, 171, 95, 39, 60, 296, 45, 60, 166, 63, 60, 298, 120, 20, 105, 122, 232, 191, 135, 40, 203, 64, 194, 62, 76, 72, 172, 229, 71, 197, 156, 152, 295, 94, 22, 33, 167, 222, 306, 238, 66, 237, 134, 139, 98, 123, 96, 220, 276, 281, 59, 192, 88, 48, 301, 174, 202, 272, 219, 114, 271, 282, 193, 287, 76, 115, 200, 262, 180, 137, 186, 199, 185, 183, 175, 169, 152, 172, 177, 192, 146, 143, 176, 181, 210, 189, 178, 32, 146, 188, 112, 189, 159, 165, 174, 185, 148, 203, 65, 102, 114, 57, 107, 37, 295, 267, 130, 48, 111, 81, 65, 68, 271, 17, 270, 51, 270, 229, 271, 328, 269, 304, 271, 301, 461, 278, 216, 76, 18, 203, 247, 205, 209, 255, 20, 273, 19, 25, 232, 57, 209, 124, 40, 75, 139, 45, 29, 91, 48, 84, 61, 59, 242, 439, 34, 27, 256, 207, 361, 58, 98, 105, 275, 22, 411, 213, 112, 119, 275, 266, 207, 241, 119, 149, 283, 151, 326, 89, 357, 69, 100, 46, 187, 63, 164, 16, 63, 39, 29, 39, 56, 23, 38, 28, 107, 193, 435, 31, 58, 81, 101, 87, 91, 64, 22, 32, 52, 57, 38, 25, 67, 84, 32, 36, 51, 24, 30, 36, 82, 17, 28, 110, 128, 78, 93, 156, 77, 37, 47, 43, 81, 176, 21, 97, 56, 15, 362, 36, 42, 121, 103, 42, 19, 35, 64, 96, 33, 199, 41, 33, 43, 42, 93, 347, 72, 84, 138, 77, 65, 91, 81, 21, 99, 43, 76, 39, 22, 36, 30, 44, 156, 175, 92, 39, 45, 131, 21, 32, 463, 411, 84, 154, 26, 40, 40, 77, 37, 87, 68, 49, 20, 37, 30, 73, 353, 19, 95, 26, 132, 64, 49, 73, 66, 29, 46, 62, 171, 37, 39, 101, 21, 28, 125, 111, 26, 58, 32, 46, 106, 234, 49, 33, 58, 57, 34, 32, 72, 17, 32, 69, 80, 57, 75, 20, 47, 17, 36, 23, 65, 82, 48, 15, 70, 38, 201, 31, 30, 29, 61, 40, 48, 85, 46, 26, 37, 37, 94, 19, 28, 357, 24, 64, 31, 331, 70, 60, 399, 51, 49, 115, 41, 76, 121, 356, 364, 43, 82, 61, 182, 162, 41, 80, 54, 41, 20, 22, 24, 112, 88, 25, 186, 108, 54, 89, 35, 60, 85, 98, 103, 106, 120, 86, 44, 187, 87, 35, 30, 73, 21, 99, 64, 374, 78, 38, 47, 78, 58, 78, 135, 22, 51, 66, 17, 53, 104, 129, 71, 44, 52, 70, 211, 285, 23, 176, 18, 67, 110, 43, 34, 118, 19, 13, 53, 74, 20, 57, 112, 16, 20, 218, 166, 110, 51, 112, 24, 46, 59, 429, 474, 185, 194, 64, 69, 87, 96, 44, 60, 71, 109, 49, 163, 28, 17, 89, 70, 153, 17, 204, 92, 33, 98, 46, 129, 19, 21, 166, 25, 75, 147, 69, 24, 19, 203, 64, 108, 107, 130, 105, 91, 49, 168, 100, 172, 110, 28, 191, 19, 36, 18, 49, 75, 21, 31, 93, 141, 16, 72, 32, 33, 269, 186, 209, 164, 25, 19, 42, 114, 17, 35, 84, 105, 24, 24, 16, 36, 106, 90, 149, 35, 28, 63, 57, 28, 112, 183, 102, 133, 48, 40, 26, 130, 17, 43, 65, 75, 47, 27, 39, 72, 120, 44, 37, 49, 17, 55, 91, 90, 104, 104, 87, 43, 24, 81, 25, 23, 23, 29, 38, 19, 16, 26, 32, 113, 19, 57, 74, 51, 48, 41, 19, 59, 86, 20, 50, 77, 41, 44, 17, 24, 22, 73, 410, 69, 84, 40, 12, 112, 23, 109, 83, 129, 81, 34, 144, 15, 187, 81, 63, 64, 102, 61, 23, 23, 79, 98, 24, 78, 242, 20, 110, 195, 272, 37, 47, 28, 15, 320, 17, 40, 41, 104, 91, 29, 30, 49, 94, 165, 107, 14, 31, 210, 47, 49, 20, 21, 347, 353, 161, 238, 135, 39, 47, 19, 165, 90, 17, 147, 90, 86, 22, 89, 22, 48, 47, 175, 167, 71, 48, 29, 23, 90, 91, 50, 27, 70, 77, 26, 113, 17, 21, 21, 54, 16, 124, 410, 85, 59, 190, 27, 64, 93, 121, 15, 66, 64, 69, 49, 95, 18, 40, 189, 52, 106, 37, 135, 83, 41, 19, 167, 23, 114, 66, 61, 168, 119, 53, 205, 20, 17, 70, 187, 18, 143, 32, 319, 283, 23, 83, 16, 180, 16, 52, 80, 94, 61, 20, 22, 138, 61, 181, 122, 45, 67, 429, 31, 35, 27, 65, 58, 48, 44, 28, 74, 15, 242, 90, 245, 40, 436, 95, 25, 22, 391, 37, 35, 169, 67, 158, 41, 72, 52, 61, 63, 54, 54, 64, 127, 53, 153, 388, 65, 17, 53, 84, 59, 121, 28, 76, 55, 17, 176, 196, 207, 176, 218, 198, 192, 174, 177, 180, 323, 218, 260, 428, 413, 350, 362, 345, 353, 345, 328, 70, 506, 296, 350, 402, 186, 183, 83, 171, 376, 359, 48, 140, 521, 24, 369, 411, 357, 392, 174, 363, 47, 339, 325, 357, 34, 378, 19, 18, 320, 115, 205, 343, 536, 345, 384, 349, 20, 462, 209, 359, 174, 184, 42, 123, 345, 360, 326, 326, 348, 341, 351, 271, 371, 194, 44, 528, 205, 80, 357, 232, 263, 20, 361, 23, 444, 471, 438, 497, 30, 337, 407, 367, 457, 75, 467, 320, 355, 79, 199, 362, 30, 54, 17, 412, 482, 24, 28, 479, 183, 224, 71, 26, 22, 379, 29, 26, 27, 187, 176, 375, 15, 480, 265, 339, 56, 429, 333, 122, 503, 214, 325, 506, 480, 346, 370, 27, 339, 114, 226, 357, 355, 360, 324, 98, 35, 318, 410, 201, 212, 162, 46, 319, 437, 168, 226, 106, 26, 122, 332, 382, 348, 425, 195, 386, 372, 398, 361, 329, 55, 175, 367, 97, 390, 80, 328, 380, 206, 356, 175, 347, 132, 355, 77, 211, 481, 102, 381, 433, 358, 332, 499, 364, 344, 394, 348, 374, 340, 65, 358, 369, 342, 354, 18, 58, 357, 324, 373, 91, 161, 214, 358, 90, 39, 528, 425, 63, 346, 111, 326, 234, 210, 360, 192, 359, 41, 19, 211, 355, 194, 338, 221, 296, 496, 338, 360, 484, 416, 18, 371, 362, 279, 382, 193, 548, 421, 372, 415, 71, 362, 366, 345, 181, 358, 319, 32, 376, 338, 340, 446, 356, 211, 229, 44, 361, 342, 361, 73, 56, 356, 37, 569, 416, 503, 312, 236, 150, 336, 31, 18, 38, 30, 370, 17, 350, 179, 377, 173, 372, 33, 503, 359, 86, 339, 369, 417, 393, 249, 94, 55, 362, 407, 204, 49, 23, 358, 385, 68, 17, 191, 358, 198, 359, 365, 171, 70, 358, 16, 42, 215, 240, 106, 190, 29, 337, 516, 174, 337, 326, 528, 76, 345, 382, 323, 316, 406, 347, 234, 188, 377, 17, 442, 381, 330, 183, 330, 318, 382, 317, 334, 188, 324, 237, 325, 174, 336, 330, 316, 368, 322, 127, 316, 239, 51, 355, 181, 216, 363, 181, 519, 60, 353, 28, 70, 36, 503, 319, 297, 331, 369, 321, 406, 322, 176, 156, 336, 333, 224, 76, 91, 366, 74, 225, 359, 370, 38, 38, 55, 386, 339, 337, 365, 544, 15, 162, 37, 376, 40, 339, 27, 68, 154, 347, 478, 297, 174, 157, 219, 171, 182, 175, 179, 174, 169, 183, 170, 178, 171, 172, 193, 210, 214, 201, 363, 181, 347, 379, 459, 332, 328, 342, 355, 365, 332, 338, 352, 47, 253, 21, 250, 501, 358, 248, 24, 329, 351, 15, 46, 91, 49, 337, 182, 224, 193, 411, 528, 354, 333, 24, 239, 185, 346, 484, 406, 209, 358, 337, 465, 381, 15, 450, 197, 235, 245, 29, 335, 346, 305, 341, 347, 62, 362, 41, 57, 22, 20, 175, 337, 174, 325, 189, 643, 52, 249, 324, 323, 162, 317, 328, 464, 174, 25, 17, 62, 413, 57, 363, 464, 379, 27, 413, 565, 359, 512, 418, 173, 349, 385, 335, 182, 14, 188, 346, 347, 83, 96, 27, 371, 218, 20, 362, 363, 434, 373, 321, 374, 191, 214, 359, 375, 178, 358, 383, 183, 361, 332, 298, 192, 180, 22, 93, 201, 196, 204, 65, 202, 232, 188, 197, 205, 206, 256, 189, 19, 73, 50, 225, 189, 19, 55, 40, 166, 29, 188, 205, 19, 265, 185, 184, 38, 74, 46, 65, 227, 197, 183, 191, 185, 182, 324, 190, 199, 169, 186, 240, 147, 116, 234, 186, 48, 33, 52, 208, 219, 45, 114, 211, 187, 151, 33, 55, 183, 489, 180, 410, 439, 199, 199, 28, 213, 43, 192, 126, 54, 54, 16, 298, 234, 72, 42, 226, 47, 184, 26, 185, 182, 186, 208, 20, 21, 203, 25, 207, 208, 46, 39, 64, 220, 218, 194, 220, 234, 63, 28, 47, 180, 126, 108, 237, 152, 244, 185, 185, 28, 1002, 171, 17, 37, 17, 188, 216, 182, 186, 65, 225, 29, 179, 81, 119, 195, 29, 37, 180, 218, 203, 84, 49, 204, 231, 188, 276, 36, 182, 216, 268, 190, 32, 105, 17, 208, 190, 20, 189, 216, 184, 67, 41, 85, 185, 213, 207, 163, 38, 198, 214, 165, 59, 184, 287, 189, 186, 204, 21, 43, 83, 35, 231, 211, 95, 177, 215, 190, 207, 239, 50, 60, 182, 183, 232, 35, 33, 186, 32, 70, 243, 186, 48, 205, 181, 228, 190, 62, 220, 67, 71, 66, 16, 29, 379, 235, 189, 250, 164, 185, 180, 181, 183, 194, 182, 186, 212, 187, 185, 183, 184, 180, 187, 228, 203, 190, 216, 196, 180, 185, 191, 214, 204, 269, 187, 183, 201, 189, 184, 188, 202, 216, 43, 55, 204, 89, 184, 32, 49, 36, 65, 199, 113, 74, 182, 204, 200, 195, 184, 160, 165, 181, 55, 43, 17, 48, 200, 188, 241, 191, 65]\n",
      "3381\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string operation on non-string array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbuild_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_train_dataset, build_missing_link_dataset\n\u001b[0;32m----> 3\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_train_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43madjacency_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaccard_similarity_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_link_candidates_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mcommon_neighbors_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_neighbors_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m missing_link_df \u001b[38;5;241m=\u001b[39m build_missing_link_dataset(adjacency_matrix, jaccard_similarity_matrix, missing_link_candidates_matrix, \n\u001b[1;32m      7\u001b[0m                                             common_neighbors_matrix, total_neighbors_matrix, graph, cluster_labels, categories_dict)\n\u001b[1;32m      8\u001b[0m train_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/Documents/Associazioni/BSML/Missing_Knowledge_Links_WIkipedia/build_dataset.py:93\u001b[0m, in \u001b[0;36mbuild_train_dataset\u001b[0;34m(adjacency_matrix, similarity_matrix, missing_link_matrix, common_neighbors_matrix, total_neighbors_matrix, graph, cluster_labels, categories_dict)\u001b[0m\n\u001b[1;32m     90\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(categories_dict[node_j]), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m substring \u001b[38;5;129;01min\u001b[39;00m substring_to_remove_categories:\n\u001b[0;32m---> 93\u001b[0m     mask \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcategories_j\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubstring\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     95\u001b[0m categories_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(categories_j[\u001b[38;5;241m~\u001b[39mmask])\n\u001b[1;32m     96\u001b[0m filtered_categories_dict[node_j] \u001b[38;5;241m=\u001b[39m categories_j\n",
      "File \u001b[0;32m~/Documents/Associazioni/BSML/Missing_Knowledge_Links_WIkipedia/.venv/lib/python3.12/site-packages/numpy/core/defchararray.py:780\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(a, sub, start, end)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_count_dispatcher)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind\u001b[39m(a, sub, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    744\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;124;03m    For each element, return the lowest index in the string where\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;124;03m    substring `sub` is found.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    778\u001b[0m \n\u001b[1;32m    779\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_vec_string\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mint_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfind\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_clean_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: string operation on non-string array"
     ]
    }
   ],
   "source": [
    "from build_dataset import build_train_dataset, build_missing_link_dataset\n",
    "\n",
    "train_df = build_train_dataset(adjacency_matrix, jaccard_similarity_matrix, missing_link_candidates_matrix, \n",
    "                               common_neighbors_matrix, total_neighbors_matrix, graph, cluster_labels, categories_dict)\n",
    "\n",
    "missing_link_df = build_missing_link_dataset(adjacency_matrix, jaccard_similarity_matrix, missing_link_candidates_matrix, \n",
    "                                            common_neighbors_matrix, total_neighbors_matrix, graph, cluster_labels, categories_dict)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the dataset into train and test\n",
    "X = train_df.drop(columns=['Link'])\n",
    "y = train_df['Link']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "\n",
      "Best Score (roc_auc): \u001b[1m0.9938086057268922\u001b[0m\n",
      "accuracy: 0.9957497593022988\n",
      "precision: 0.42631893748906485\n",
      "recall: 0.9914266176126523\n",
      "f1: 0.5379601558592585\n",
      "\n",
      "Best Hyperparameters:\n",
      "alpha: 0.1\n",
      "max_depth: 3\n",
      "n_estimators: 100\n",
      "objective: binary:logistic\n",
      "scale_pos_weight: 779.3897784601886\n",
      "\n",
      "Optimal Threshold: 1.5000771e-32\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from tune_model import tune\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "\n",
    "# train the model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# calculate scale_pos_weight\n",
    "scale_pos_weight = np.sum(y_train == 0) / np.sum(y_train == 1)\n",
    "\n",
    "# set parameters for grid search\n",
    "space = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [3],\n",
    "    'scale_pos_weight': [scale_pos_weight],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'alpha': [0.1]\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "best_params, best_model = tune(X, y, space, scoring, \n",
    "                            model, modeltype='clf', search_type='grid', n_iter_random=100,\n",
    "                            n_splits=3, n_repeats=1, random_state=1,\n",
    "                            verbose=True, display_plots=0, refit='roc_auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9969846525899861\n",
      "Precision: 0.30828100470957615\n",
      "Recall: 0.968557336621455\n",
      "F1 score: 0.4676987198571003\n",
      "ROC AUC: 0.9827904612434959\n",
      "Confusion matrix: \n",
      "[[1180786    3525]\n",
      " [     51    1571]]\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 score: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"Confusion matrix: \")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaius Terentilius Harsa <-- 1.000 --> 1917 code of canon law\n",
      "Gaius Terentilius Harsa <-- 1.000 --> great seal of the united states\n",
      "Gaius Terentilius Harsa <-- 1.000 --> early modern period\n",
      "Gaius Terentilius Harsa <-- 1.000 --> epigraphy\n",
      "Gaius Terentilius Harsa <-- 1.000 --> esse quam videri\n",
      "Gaius Terentilius Harsa <-- 1.000 --> eton college\n",
      "Gaius Terentilius Harsa <-- 1.000 --> etruscan alphabet\n",
      "Gaius Terentilius Harsa <-- 1.000 --> etruscan language\n",
      "Gaius Terentilius Harsa <-- 1.000 --> faliscan language\n",
      "Gaius Terentilius Harsa <-- 1.000 --> floruit\n",
      "Gaius Terentilius Harsa <-- 1.000 --> franks casket\n",
      "Gaius Terentilius Harsa <-- 1.000 --> frederic m. wheelock\n",
      "Gaius Terentilius Harsa <-- 1.000 --> fricative consonant\n",
      "Gaius Terentilius Harsa <-- 1.000 --> fusional language\n",
      "Gaius Terentilius Harsa <-- 1.000 --> gemination\n",
      "Gaius Terentilius Harsa <-- 1.000 --> genitive case\n",
      "Gaius Terentilius Harsa <-- 1.000 --> george buchanan\n",
      "Gaius Terentilius Harsa <-- 1.000 --> germanic people\n",
      "Gaius Terentilius Harsa <-- 1.000 --> gerund\n",
      "Gaius Terentilius Harsa <-- 1.000 --> gerundive\n",
      "Gaius Terentilius Harsa <-- 1.000 --> grammar\n",
      "Gaius Terentilius Harsa <-- 1.000 --> grammatical conjugation\n",
      "Gaius Terentilius Harsa <-- 1.000 --> grammatical gender\n",
      "Gaius Terentilius Harsa <-- 1.000 --> e pluribus unum\n",
      "Gaius Terentilius Harsa <-- 1.000 --> dum spiro spero\n",
      "Gaius Terentilius Harsa <-- 1.000 --> duenos inscription\n",
      "Gaius Terentilius Harsa <-- 1.000 --> croatian parliament\n",
      "Gaius Terentilius Harsa <-- 1.000 --> comparative and superlative\n",
      "Gaius Terentilius Harsa <-- 1.000 --> compound (linguistics)\n",
      "Gaius Terentilius Harsa <-- 1.000 --> connecticut\n",
      "Gaius Terentilius Harsa <-- 1.000 --> conrad celtes\n",
      "Gaius Terentilius Harsa <-- 1.000 --> corpus inscriptionum latinarum\n",
      "Gaius Terentilius Harsa <-- 1.000 --> council of the european union\n",
      "Gaius Terentilius Harsa <-- 1.000 --> croatia\n",
      "Gaius Terentilius Harsa <-- 1.000 --> croatian latin literature\n",
      "Gaius Terentilius Harsa <-- 1.000 --> croatian national bank\n",
      "Gaius Terentilius Harsa <-- 1.000 --> croatian language\n",
      "Gaius Terentilius Harsa <-- 1.000 --> descartes\n",
      "Gaius Terentilius Harsa <-- 1.000 --> cupid\n",
      "Gaius Terentilius Harsa <-- 1.000 --> curlie\n",
      "Gaius Terentilius Harsa <-- 1.000 --> curse tablets\n",
      "Gaius Terentilius Harsa <-- 1.000 --> czech language\n",
      "Gaius Terentilius Harsa <-- 1.000 --> dative case\n",
      "Gaius Terentilius Harsa <-- 1.000 --> dead language\n",
      "Gaius Terentilius Harsa <-- 1.000 --> declension\n",
      "Gaius Terentilius Harsa <-- 1.000 --> department of justice (philippines)\n",
      "Gaius Terentilius Harsa <-- 1.000 --> deponent verb\n",
      "Gaius Terentilius Harsa <-- 1.000 --> grammatical tense\n",
      "Gaius Terentilius Harsa <-- 1.000 --> greek alphabet\n",
      "Gaius Terentilius Harsa <-- 1.000 --> commentarii de bello gallico\n",
      "Gaius Terentilius Harsa <-- 1.000 --> greek and latin roots in english\n",
      "Gaius Terentilius Harsa <-- 1.000 --> instrumental case\n",
      "Gaius Terentilius Harsa <-- 1.000 --> interlingua\n",
      "Gaius Terentilius Harsa <-- 1.000 --> international roman law moot court\n",
      "Gaius Terentilius Harsa <-- 1.000 --> international communication\n",
      "Gaius Terentilius Harsa <-- 1.000 --> interpunct\n",
      "Gaius Terentilius Harsa <-- 1.000 --> interword spacing\n",
      "Gaius Terentilius Harsa <-- 1.000 --> iowa state university\n",
      "Gaius Terentilius Harsa <-- 1.000 --> isaac casaubon\n",
      "Gaius Terentilius Harsa <-- 1.000 --> isaac newton\n",
      "Gaius Terentilius Harsa <-- 1.000 --> italian peninsula\n",
      "Gaius Terentilius Harsa <-- 1.000 --> italic languages\n",
      "Gaius Terentilius Harsa <-- 1.000 --> janus pannonius\n",
      "Gaius Terentilius Harsa <-- 1.000 --> joseph scaliger\n",
      "Gaius Terentilius Harsa <-- 1.000 --> judeo-latin\n",
      "Gaius Terentilius Harsa <-- 1.000 --> jughead (lost)\n",
      "Gaius Terentilius Harsa <-- 1.000 --> kansas\n",
      "Gaius Terentilius Harsa <-- 1.000 --> kingdom of hungary\n",
      "Gaius Terentilius Harsa <-- 1.000 --> kingdom of poland\n",
      "Gaius Terentilius Harsa <-- 1.000 --> koine greek\n",
      "Gaius Terentilius Harsa <-- 1.000 --> labial consonant\n",
      "Gaius Terentilius Harsa <-- 1.000 --> labialisation\n",
      "Gaius Terentilius Harsa <-- 1.000 --> instruction in latin\n",
      "Gaius Terentilius Harsa <-- 1.000 --> inkhorn term\n",
      "Gaius Terentilius Harsa <-- 1.000 --> infinitive\n",
      "Gaius Terentilius Harsa <-- 1.000 --> helvetia\n",
      "Gaius Terentilius Harsa <-- 1.000 --> greek art\n",
      "Gaius Terentilius Harsa <-- 1.000 --> gymnasium (germany)\n",
      "Gaius Terentilius Harsa <-- 1.000 --> gymnasium (school)\n",
      "Gaius Terentilius Harsa <-- 1.000 --> haberdashers' aske's boys' school\n",
      "Gaius Terentilius Harsa <-- 1.000 --> hadrian's wall\n",
      "Gaius Terentilius Harsa <-- 1.000 --> harrow school\n",
      "Gaius Terentilius Harsa <-- 1.000 --> harry potter\n",
      "Gaius Terentilius Harsa <-- 1.000 --> harvard university\n",
      "Gaius Terentilius Harsa <-- 1.000 --> harvard university press\n",
      "Gaius Terentilius Harsa <-- 1.000 --> hernici\n",
      "Gaius Terentilius Harsa <-- 1.000 --> incunabula\n",
      "Gaius Terentilius Harsa <-- 1.000 --> hiberno-latin\n",
      "Gaius Terentilius Harsa <-- 1.000 --> history of taranto\n",
      "Gaius Terentilius Harsa <-- 1.000 --> holy roman empire\n",
      "Gaius Terentilius Harsa <-- 1.000 --> holy see\n",
      "Gaius Terentilius Harsa <-- 1.000 --> how the grinch stole christmas!\n",
      "Gaius Terentilius Harsa <-- 1.000 --> hungarian language\n",
      "Gaius Terentilius Harsa <-- 1.000 --> hungary\n",
      "Gaius Terentilius Harsa <-- 1.000 --> hybrid word\n",
      "Gaius Terentilius Harsa <-- 1.000 --> igor stravinsky\n",
      "Gaius Terentilius Harsa <-- 1.000 --> common language\n",
      "Gaius Terentilius Harsa <-- 1.000 --> colosseum\n",
      "Gaius Terentilius Harsa <-- 1.000 --> united states space force\n",
      "Gaius Terentilius Harsa <-- 1.000 --> acta apostolicae sedis\n"
     ]
    }
   ],
   "source": [
    "# save the columns 'node1', 'node2' into arrays\n",
    "node1 = missing_link_df['node 1'].values\n",
    "node2 = missing_link_df['node 2'].values\n",
    "\n",
    "# remove the columns 'node1', 'node2' from the dataframe\n",
    "missing_link_df = missing_link_df.drop(columns=['node 1', 'node 2'])\n",
    "\n",
    "# predict link probabilities for the missing link candidates\n",
    "link_probabilities = best_model.predict_proba(missing_link_df)[:, 1]\n",
    "\n",
    "# add the link probabilities to a new column called 'Link Probability'\n",
    "missing_link_df['Link Probability'] = link_probabilities\n",
    "missing_link_df['node 1'] = node1\n",
    "missing_link_df['node 2'] = node2\n",
    "\n",
    "# keep only probabilities above the optimal threshold\n",
    "missing_link_df = missing_link_df[missing_link_df['Link Probability'] > 0.5]\n",
    "\n",
    "# sort the missing link candidates by link probability\n",
    "missing_link_df = missing_link_df.sort_values(by='Link Probability', ascending=False)\n",
    "\n",
    "for i in range(100):\n",
    "    node1 = missing_link_df.iloc[i]['node 1']\n",
    "    node2 = missing_link_df.iloc[i]['node 2']\n",
    "    link_probability = missing_link_df.iloc[i]['Link Probability']\n",
    "\n",
    "    print(f\"{node1} <-- {link_probability:.3f} --> {node2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaius Terentilius Harsa <-- 1.000 --> 1917 code of canon law\n",
      "Gaius Terentilius Harsa <-- 1.000 --> great seal of the united states\n",
      "Gaius Terentilius Harsa <-- 1.000 --> early modern period\n",
      "Gaius Terentilius Harsa <-- 1.000 --> epigraphy\n",
      "Gaius Terentilius Harsa <-- 1.000 --> esse quam videri\n",
      "Gaius Terentilius Harsa <-- 1.000 --> eton college\n",
      "Gaius Terentilius Harsa <-- 1.000 --> etruscan alphabet\n",
      "Gaius Terentilius Harsa <-- 1.000 --> etruscan language\n",
      "Gaius Terentilius Harsa <-- 1.000 --> faliscan language\n",
      "Gaius Terentilius Harsa <-- 1.000 --> floruit\n",
      "Gaius Terentilius Harsa <-- 1.000 --> franks casket\n",
      "Gaius Terentilius Harsa <-- 1.000 --> frederic m. wheelock\n",
      "Gaius Terentilius Harsa <-- 1.000 --> fricative consonant\n",
      "Gaius Terentilius Harsa <-- 1.000 --> fusional language\n",
      "Gaius Terentilius Harsa <-- 1.000 --> gemination\n",
      "Gaius Terentilius Harsa <-- 1.000 --> genitive case\n",
      "Gaius Terentilius Harsa <-- 1.000 --> george buchanan\n",
      "Gaius Terentilius Harsa <-- 1.000 --> germanic people\n",
      "Gaius Terentilius Harsa <-- 1.000 --> gerund\n",
      "Gaius Terentilius Harsa <-- 1.000 --> gerundive\n",
      "Gaius Terentilius Harsa <-- 1.000 --> grammar\n",
      "Gaius Terentilius Harsa <-- 1.000 --> grammatical conjugation\n",
      "Gaius Terentilius Harsa <-- 1.000 --> grammatical gender\n",
      "Gaius Terentilius Harsa <-- 1.000 --> e pluribus unum\n",
      "Gaius Terentilius Harsa <-- 1.000 --> dum spiro spero\n",
      "Gaius Terentilius Harsa <-- 1.000 --> duenos inscription\n",
      "Gaius Terentilius Harsa <-- 1.000 --> croatian parliament\n",
      "Gaius Terentilius Harsa <-- 1.000 --> comparative and superlative\n",
      "Gaius Terentilius Harsa <-- 1.000 --> compound (linguistics)\n",
      "Gaius Terentilius Harsa <-- 1.000 --> connecticut\n",
      "Gaius Terentilius Harsa <-- 1.000 --> conrad celtes\n",
      "Gaius Terentilius Harsa <-- 1.000 --> corpus inscriptionum latinarum\n",
      "Gaius Terentilius Harsa <-- 1.000 --> council of the european union\n",
      "Gaius Terentilius Harsa <-- 1.000 --> croatia\n",
      "Gaius Terentilius Harsa <-- 1.000 --> croatian latin literature\n",
      "Gaius Terentilius Harsa <-- 1.000 --> croatian national bank\n",
      "Gaius Terentilius Harsa <-- 1.000 --> croatian language\n",
      "Gaius Terentilius Harsa <-- 1.000 --> descartes\n",
      "Gaius Terentilius Harsa <-- 1.000 --> cupid\n",
      "Gaius Terentilius Harsa <-- 1.000 --> curlie\n",
      "Gaius Terentilius Harsa <-- 1.000 --> curse tablets\n",
      "Gaius Terentilius Harsa <-- 1.000 --> czech language\n",
      "Gaius Terentilius Harsa <-- 1.000 --> dative case\n",
      "Gaius Terentilius Harsa <-- 1.000 --> dead language\n",
      "Gaius Terentilius Harsa <-- 1.000 --> declension\n",
      "Gaius Terentilius Harsa <-- 1.000 --> department of justice (philippines)\n",
      "Gaius Terentilius Harsa <-- 1.000 --> deponent verb\n",
      "Gaius Terentilius Harsa <-- 1.000 --> grammatical tense\n",
      "Gaius Terentilius Harsa <-- 1.000 --> greek alphabet\n",
      "Gaius Terentilius Harsa <-- 1.000 --> commentarii de bello gallico\n",
      "Gaius Terentilius Harsa <-- 1.000 --> greek and latin roots in english\n",
      "Gaius Terentilius Harsa <-- 1.000 --> instrumental case\n",
      "Gaius Terentilius Harsa <-- 1.000 --> interlingua\n",
      "Gaius Terentilius Harsa <-- 1.000 --> international roman law moot court\n",
      "Gaius Terentilius Harsa <-- 1.000 --> international communication\n",
      "Gaius Terentilius Harsa <-- 1.000 --> interpunct\n",
      "Gaius Terentilius Harsa <-- 1.000 --> interword spacing\n",
      "Gaius Terentilius Harsa <-- 1.000 --> iowa state university\n",
      "Gaius Terentilius Harsa <-- 1.000 --> isaac casaubon\n",
      "Gaius Terentilius Harsa <-- 1.000 --> isaac newton\n",
      "Gaius Terentilius Harsa <-- 1.000 --> italian peninsula\n",
      "Gaius Terentilius Harsa <-- 1.000 --> italic languages\n",
      "Gaius Terentilius Harsa <-- 1.000 --> janus pannonius\n",
      "Gaius Terentilius Harsa <-- 1.000 --> joseph scaliger\n",
      "Gaius Terentilius Harsa <-- 1.000 --> judeo-latin\n",
      "Gaius Terentilius Harsa <-- 1.000 --> jughead (lost)\n",
      "Gaius Terentilius Harsa <-- 1.000 --> kansas\n",
      "Gaius Terentilius Harsa <-- 1.000 --> kingdom of hungary\n",
      "Gaius Terentilius Harsa <-- 1.000 --> kingdom of poland\n",
      "Gaius Terentilius Harsa <-- 1.000 --> koine greek\n",
      "Gaius Terentilius Harsa <-- 1.000 --> labial consonant\n",
      "Gaius Terentilius Harsa <-- 1.000 --> labialisation\n",
      "Gaius Terentilius Harsa <-- 1.000 --> instruction in latin\n",
      "Gaius Terentilius Harsa <-- 1.000 --> inkhorn term\n",
      "Gaius Terentilius Harsa <-- 1.000 --> infinitive\n",
      "Gaius Terentilius Harsa <-- 1.000 --> helvetia\n",
      "Gaius Terentilius Harsa <-- 1.000 --> greek art\n",
      "Gaius Terentilius Harsa <-- 1.000 --> gymnasium (germany)\n",
      "Gaius Terentilius Harsa <-- 1.000 --> gymnasium (school)\n",
      "Gaius Terentilius Harsa <-- 1.000 --> haberdashers' aske's boys' school\n",
      "Gaius Terentilius Harsa <-- 1.000 --> hadrian's wall\n",
      "Gaius Terentilius Harsa <-- 1.000 --> harrow school\n",
      "Gaius Terentilius Harsa <-- 1.000 --> harry potter\n",
      "Gaius Terentilius Harsa <-- 1.000 --> harvard university\n",
      "Gaius Terentilius Harsa <-- 1.000 --> harvard university press\n",
      "Gaius Terentilius Harsa <-- 1.000 --> hernici\n",
      "Gaius Terentilius Harsa <-- 1.000 --> incunabula\n",
      "Gaius Terentilius Harsa <-- 1.000 --> hiberno-latin\n",
      "Gaius Terentilius Harsa <-- 1.000 --> history of taranto\n",
      "Gaius Terentilius Harsa <-- 1.000 --> holy roman empire\n",
      "Gaius Terentilius Harsa <-- 1.000 --> holy see\n",
      "Gaius Terentilius Harsa <-- 1.000 --> how the grinch stole christmas!\n",
      "Gaius Terentilius Harsa <-- 1.000 --> hungarian language\n",
      "Gaius Terentilius Harsa <-- 1.000 --> hungary\n",
      "Gaius Terentilius Harsa <-- 1.000 --> hybrid word\n",
      "Gaius Terentilius Harsa <-- 1.000 --> igor stravinsky\n",
      "Gaius Terentilius Harsa <-- 1.000 --> common language\n",
      "Gaius Terentilius Harsa <-- 1.000 --> colosseum\n",
      "Gaius Terentilius Harsa <-- 1.000 --> united states space force\n",
      "Gaius Terentilius Harsa <-- 1.000 --> acta apostolicae sedis\n"
     ]
    }
   ],
   "source": [
    "# find missing links where either node1 or node2 are in the same cluster as the start page\n",
    "start_page_cluster = cluster_labels[0]\n",
    "node1_cluster_mask = missing_link_df['cluster node 1'].values == start_page_cluster\n",
    "node2_cluster_mask = missing_link_df['cluster node 2'].values == start_page_cluster\n",
    "start_page_cluster_mask = node1_cluster_mask | node2_cluster_mask\n",
    "\n",
    "start_page_cluster_missing_links = missing_link_df[start_page_cluster_mask]\n",
    "\n",
    "iters = min(100, len(start_page_cluster_missing_links))\n",
    "\n",
    "for i in range(iters):\n",
    "    node1 = start_page_cluster_missing_links.iloc[i]['node 1']\n",
    "    node2 = start_page_cluster_missing_links.iloc[i]['node 2']\n",
    "    link_probability = start_page_cluster_missing_links.iloc[i]['Link Probability']\n",
    "\n",
    "    print(f\"{node1} <-- {link_probability:.3f} --> {node2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Common Neighbors</th>\n",
       "      <th>Total Neighbors</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Common Categories</th>\n",
       "      <th>Total Categories</th>\n",
       "      <th>n_categories node 1</th>\n",
       "      <th>n_categories node 2</th>\n",
       "      <th>cluster node 1</th>\n",
       "      <th>cluster node 2</th>\n",
       "      <th>Link Probability</th>\n",
       "      <th>node 1</th>\n",
       "      <th>node 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Gaius Terentilius Harsa</td>\n",
       "      <td>1917 code of canon law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Gaius Terentilius Harsa</td>\n",
       "      <td>great seal of the united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Gaius Terentilius Harsa</td>\n",
       "      <td>early modern period</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Gaius Terentilius Harsa</td>\n",
       "      <td>epigraphy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Gaius Terentilius Harsa</td>\n",
       "      <td>esse quam videri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Common Neighbors  Total Neighbors  Similarity  Common Categories  \\\n",
       "0                  1.0             21.0    0.047619                0.0   \n",
       "2098               1.0             21.0    0.047619                0.0   \n",
       "2076               1.0             21.0    0.047619                0.0   \n",
       "2077               1.0             21.0    0.047619                0.0   \n",
       "2078               1.0             21.0    0.047619                0.0   \n",
       "\n",
       "      Total Categories  n_categories node 1  n_categories node 2  \\\n",
       "0                  4.0                  4.0                  0.0   \n",
       "2098              27.0                  4.0                 23.0   \n",
       "2076              38.0                  4.0                 34.0   \n",
       "2077              32.0                  4.0                 28.0   \n",
       "2078              20.0                  4.0                 16.0   \n",
       "\n",
       "      cluster node 1  cluster node 2  Link Probability  \\\n",
       "0                0.0             0.0               1.0   \n",
       "2098             0.0             0.0               1.0   \n",
       "2076             0.0             0.0               1.0   \n",
       "2077             0.0             0.0               1.0   \n",
       "2078             0.0             0.0               1.0   \n",
       "\n",
       "                       node 1                           node 2  \n",
       "0     Gaius Terentilius Harsa           1917 code of canon law  \n",
       "2098  Gaius Terentilius Harsa  great seal of the united states  \n",
       "2076  Gaius Terentilius Harsa              early modern period  \n",
       "2077  Gaius Terentilius Harsa                        epigraphy  \n",
       "2078  Gaius Terentilius Harsa                 esse quam videri  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find missing links that include the start page if node1 or node2 is the start page\n",
    "df_missing_links_start_page = missing_link_df[(missing_link_df['node 1'] == start_page) | (missing_link_df['node 2'] == start_page)]\n",
    "\n",
    "df_missing_links_start_page.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'high-pressure cut-off switch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# use link dict to find the links of 'high-pressure cut-off switch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m high_pressure_cut_off_switch_links \u001b[38;5;241m=\u001b[39m \u001b[43mlinks_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhigh-pressure cut-off switch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinks of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh-pressure cut-off switch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m high_pressure_cut_off_switch_links:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'high-pressure cut-off switch'"
     ]
    }
   ],
   "source": [
    "# use link dict to find the links of 'high-pressure cut-off switch\n",
    "high_pressure_cut_off_switch_links = links_dict['high-pressure cut-off switch']\n",
    "\n",
    "print(f\"Links of 'high-pressure cut-off switch':\")\n",
    "for link in high_pressure_cut_off_switch_links:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = ['is', 'not']\n",
    "categories = np.array(['I am you', 'I am not you', 'I is me', 'I am not me', 'I am him', 'I am not him', 'I am her', 'I am not her', 'I am it', 'I am not it'])\n",
    "\n",
    "# use np.char.find to filter out the blacklist words\n",
    "\n",
    "for word in blacklist:\n",
    "    categories = categories[np.char.find(categories, word) == -1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
